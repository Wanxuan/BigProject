{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解压数据\n",
    "将文件下载到本地并进行解压。  \n",
    "img压缩包解压成train和test两个文件夹，其中train目录下包含十个对应特征的文件夹。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imgs\n",
      "imgs already present - Skipping extraction of imgs.zip.\n",
      "['train/c0', 'train/c1', 'train/c2', 'train/c3', 'train/c4', 'train/c5', 'train/c6', 'train/c7', 'train/c8', 'train/c9']\n",
      "22424\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "num_classes = 10\n",
    "np.random.seed(133)\n",
    "\n",
    "filename = \"imgs.zip\"\n",
    "\n",
    "def maybe_extract(filename, force=True):\n",
    "    root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .zip\n",
    "    print(root)\n",
    "    if os.path.isdir('train') and os.path.isdir('test'):\n",
    "        # You may override by setting force=True.\n",
    "        print('%s already present - Skipping extraction of %s.' % (root, filename))\n",
    "    else:\n",
    "        print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
    "        zfile = zipfile.ZipFile(filename,'r')\n",
    "        for filename in zfile.namelist():\n",
    "            zfile.extract(filename, r'.')\n",
    "        zfile.close()\n",
    "    data_folders = [os.path.join('train', d) for d in sorted(os.listdir('train'))\n",
    "                    if os.path.isdir(os.path.join('train', d))]\n",
    "    if len(data_folders) != num_classes:\n",
    "        raise Exception(\n",
    "            'Expected %d folders, ten per class. Found %d instead.' % (\n",
    "                num_classes, len(data_folders)))\n",
    "    print(data_folders)\n",
    "    return data_folders\n",
    "\n",
    "def dataset_size():\n",
    "    \n",
    "    size = 0\n",
    "    for i in range(10):\n",
    "        size += len([x for x in os.listdir(str(folders[i]))])\n",
    "    print(size)\n",
    "    return size\n",
    "\n",
    "folders = maybe_extract(filename)\n",
    "num_train = dataset_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理\n",
    "用PIL库中的Image函数调用open方法读取图片并转化为数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_height = 640\n",
    "img_width = 480\n",
    "\n",
    "def load_image(folder):\n",
    "    \n",
    "    imgs = [i for i in os.listdir(folder)]\n",
    "    num = len(imgs)\n",
    "    data = np.zeros((num, img_width, img_height, 3), dtype='uint8')\n",
    "    label = np.zeros((num,), dtype=\"uint8\")\n",
    "    for i in range(num):\n",
    "        img = Image.open(folder+\"/\"+imgs[i])\n",
    "        data[i,:,:,:] = np.asarray(img, dtype=\"uint8\")\n",
    "    label += int(folder.split(\"c\")[1])           \n",
    "    return data, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合成一个包含10类别的训练集。  \n",
    "c0：2489。   c5：2312。  \n",
    "c1：2267。   c6：2325。  \n",
    "c2：2317。   c7：2002。  \n",
    "c3：2346。   c8：1911。   \n",
    "c4：2326。   c9：2129。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/c0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'JpegImageFile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fb274669f4ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-fb274669f4ec>\u001b[0m in \u001b[0;36mmerge_folder\u001b[0;34m(folders)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mfolder_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mfolders_size\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfolder_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-8d01d22a9496>\u001b[0m in \u001b[0;36mload_image\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"uint8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/dlnd-tf-lab/lib/python3.5/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'JpegImageFile'"
     ]
    }
   ],
   "source": [
    "def merge_folder(folders):\n",
    "    \n",
    "    x_train = np.zeros((num_train, img_width, img_height, 3), dtype='uint8')\n",
    "    y_train = np.zeros((num_train,), dtype=\"uint8\")\n",
    "    folders_size = 0\n",
    "    for f in folders:\n",
    "        print(f)\n",
    "        data, label = load_image(f)\n",
    "        folder_size = data.shape[0]\n",
    "        folders_size += folder_size\n",
    "        x_train[folders_size-folder_size:folders_size,:,:,:] = data\n",
    "        y_train[folders_size-folder_size:folders_size] = label\n",
    "    return x_train, y_train\n",
    "\n",
    "x_train, y_train = merge_folder(folders)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle数据集\n",
    "将合成数据集的顺序全部重新排列。\n",
    "然后显示合成数据集的图片和标签对应的数组大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r = np.random.permutation(len(y_train))\n",
    "x_train = x_train[r,:,:,:] \n",
    "y_train = [r]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集可视化\n",
    "随机选取15组图片，并对其进行可视化。确定所显示图片与标签正确对应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "num_train = 22424\n",
    "\n",
    "for i in range(15):\n",
    "    plt.subplot(3, 5, i+1)\n",
    "    index = random.randint(0, num_train-1)\n",
    "    plt.title(str(y_train[index]))\n",
    "    plt.imshow(x_train[index])\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设计并测试一个模型架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    "# import keras\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "# from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# batch_size = 32\n",
    "# num_classes = 10\n",
    "# epochs = 200\n",
    "# data_augmentation = True\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(32, (3, 3), padding='same',\n",
    "#                  input_shape=x_train.shape[1:]))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(32, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(64, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(num_classes))\n",
    "# model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # initiate RMSprop optimizer\n",
    "# opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# # Let's train the model using RMSprop\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=opt,\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# x_train = x_train.astype('float32')\n",
    "# x_test = x_test.astype('float32')\n",
    "# x_train /= 255\n",
    "# x_test /= 255\n",
    "\n",
    "# if not data_augmentation:\n",
    "#     print('Not using data augmentation.')\n",
    "#     model.fit(x_train, y_train,\n",
    "#               batch_size=batch_size,\n",
    "#               epochs=epochs,\n",
    "#               validation_data=(x_test, y_test),\n",
    "#               shuffle=True)\n",
    "# else:\n",
    "#     print('Using real-time data augmentation.')\n",
    "#     # This will do preprocessing and realtime data augmentation:\n",
    "#     datagen = ImageDataGenerator(\n",
    "#         featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "#         samplewise_center=False,  # set each sample mean to 0\n",
    "#         featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "#         samplewise_std_normalization=False,  # divide each input by its std\n",
    "#         zca_whitening=False,  # apply ZCA whitening\n",
    "#         rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "#         width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "#         height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "#         horizontal_flip=True,  # randomly flip images\n",
    "#         vertical_flip=False)  # randomly flip images\n",
    "\n",
    "#     # Compute quantities required for feature-wise normalization\n",
    "#     # (std, mean, and principal components if ZCA whitening is applied).\n",
    "#     datagen.fit(x_train)\n",
    "\n",
    "#     # Fit the model on the batches generated by datagen.flow().\n",
    "#     model.fit_generator(datagen.flow(x_train, y_train,\n",
    "#                                      batch_size=batch_size),\n",
    "#                         steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "#                         epochs=epochs,\n",
    "#                         validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
